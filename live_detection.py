# -*- coding: utf-8 -*-
"""
Live Detection Script (YAMNet Transfer Learning Version)
"""

import os
import sys
import datetime
import pickle
import numpy as np
import sounddevice as sd
import soundfile as sf
import librosa
import tensorflow as tf
import tensorflow_hub as hub
import serial
import time

# TensorFlow log seviyesini ayarlaa
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# =============================================================================
# AYARLAR
# =============================================================================
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_PATH = os.path.join(SCRIPT_DIR, "yamnet_transfer_model.h5")
ENCODER_PATH = os.path.join(SCRIPT_DIR, "yamnet_encoder.pkl")
RECORDINGS_DIR = os.path.join(SCRIPT_DIR, "live_recordings")

# YAMNet Native Handle
YAMNET_MODEL_HANDLE = 'https://tfhub.dev/google/yamnet/1'

# YAMNet Parametreleri
SAMPLE_RATE = 16000 # YAMNet 16k zorunlu
DURATION = 5        # 5 saniyelik dinleme
CONFIDENCE_THRESHOLD = 40.0 # Transfer learning daha katÄ± olabilir, eÅŸiÄŸi ayarladÄ±k
RMS_THRESHOLD = 0.005 

# Arduino AyarlarÄ±
ARDUINO_PORT = 'COM9'
ARDUINO_BAUD = 9600

# Etiket Ã‡evirileri
LABEL_TR = {
    "hungry": "AÃ§lÄ±k ğŸ¼",
    "belly_pain": "KarÄ±n AÄŸrÄ±sÄ± ğŸ˜£",
    "burping": "Gaz/GeÄŸirme ğŸ’¨",
    "discomfort": "RahatsÄ±zlÄ±k ğŸ˜«",
    "tired": "Yorgunluk ğŸ˜´"
}

if not os.path.exists(RECORDINGS_DIR):
    os.makedirs(RECORDINGS_DIR)

# =============================================================================
# YARDIMCI FONKSÄ°YONLAR
# =============================================================================

def load_components():
    """Modelleri yÃ¼kle"""
    print("Modeller yÃ¼kleniyor (Biraz sÃ¼rebilir)...")
    try:
        # 1. YAMNet YÃ¼kle
        print("  - YAMNet indiriliyor/yÃ¼kleniyor...")
        yamnet = hub.load(YAMNET_MODEL_HANDLE)
        
        # 2. Bizim SÄ±nÄ±flandÄ±rÄ±cÄ±yÄ± YÃ¼kle
        print("  - SÄ±nÄ±flandÄ±rÄ±cÄ± yÃ¼kleniyor...")
        classifier = tf.keras.models.load_model(MODEL_PATH)
        
        # 3. Encoder YÃ¼kle
        with open(ENCODER_PATH, 'rb') as f:
            encoder = pickle.load(f)
            
        print("âœ… TÃ¼m modeller hazÄ±r.")
        return yamnet, classifier, encoder
    except Exception as e:
        print(f"âŒ Model yÃ¼kleme hatasÄ±: {e}")
        print("LÃ¼tfen Ã¶nce 'train_transfer.py' Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ±zdan emin olun.")
        sys.exit(1)

def extract_embedding(yamnet, audio_data):
    """Sesten YAMNet Ã¶zetini Ã§Ä±kar"""
    # Normalizasyon
    waveform = audio_data / np.max(np.abs(audio_data) + 1e-9)
    
    # YAMNet Ã‡alÄ±ÅŸtÄ±r
    # Ã‡Ä±ktÄ±lar: scores, embeddings, spectrogram
    _, embeddings, _ = yamnet(waveform)
    
    # Global Average Pooling (TÃ¼m zamanlarÄ±n ortalamasÄ±)
    global_embedding = tf.reduce_mean(embeddings, axis=0).numpy()
    
    # Model (1, 1024) bekliyor
    return global_embedding.reshape(1, -1)

def save_recording(audio, fs, filename_prefix="rec"):
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{filename_prefix}_{timestamp}.wav"
    filepath = os.path.join(RECORDINGS_DIR, filename)
    sf.write(filepath, audio, fs)
    return filepath

def connect_arduino():
    """Arduino'ya baÄŸlan"""
    try:
        arduino = serial.Serial(ARDUINO_PORT, ARDUINO_BAUD, timeout=1)
        time.sleep(2)  # Arduino reset bekle
        print(f"âœ… Arduino baÄŸlandÄ± ({ARDUINO_PORT})")
        return arduino
    except Exception as e:
        print(f"âš ï¸ Arduino baÄŸlantÄ± hatasÄ±: {e}")
        print("   LCD olmadan devam ediliyor...")
        return None

def send_to_arduino(arduino, label, confidence):
    """Sonucu Arduino'ya gÃ¶nder"""
    if arduino is None:
        return
    try:
        # LCD iÃ§in TÃ¼rkÃ§e karakter dÃ¼zeltme
        lcd_text = label.replace("Ä±", "i").replace("ÄŸ", "g").replace("Ã¼", "u").replace("ÅŸ", "s").replace("Ã¶", "o").replace("Ã§", "c")
        lcd_text = lcd_text.replace("Ä°", "I").replace("Ä", "G").replace("Ãœ", "U").replace("Å", "S").replace("Ã–", "O").replace("Ã‡", "C")
        # Emoji kaldÄ±r
        for emoji in ['ğŸ¼', 'ğŸ˜£', 'ğŸ’¨', 'ğŸ˜«', 'ğŸ˜´']:
            lcd_text = lcd_text.replace(emoji, '')
        lcd_text = lcd_text.strip()
        
        # Ä°ki satÄ±r: Ãœst satÄ±r sebep, alt satÄ±r gÃ¼ven
        message = f"{lcd_text[:16]}%{confidence:.0f} Guven"
        arduino.write(f"{message}\n".encode('ascii', errors='ignore'))
        print(f"ğŸ“Ÿ LCD'ye gÃ¶nderildi: {lcd_text}")
    except Exception as e:
        print(f"âš ï¸ Arduino gÃ¶nderim hatasÄ±: {e}")

def select_microphone():
    print("\nğŸ§ MÄ°KROFON SEÃ‡Ä°MÄ°")
    print("-" * 30)
    devices = sd.query_devices()
    input_devices = []
    
    for i, device in enumerate(devices):
        if device['max_input_channels'] > 0:
            input_devices.append((i, device))
            print(f"[{i}] {device['name']}")
    
    if not input_devices:
        print("âŒ HiÃ§bir mikrofon bulunamadÄ±!")
        sys.exit(1)
        
    print("-" * 30)
    
    while True:
        try:
            selection = input("LÃ¼tfen mikrofon numarasÄ±nÄ± girin (VarsayÄ±lan iÃ§in Enter): ")
            if selection.strip() == "":
                return None
            idx = int(selection)
            valid_indices = [d[0] for d in input_devices]
            if idx in valid_indices:
                return idx
            print("âŒ GeÃ§ersiz numara.")
        except ValueError:
            print("âŒ SayÄ± girin.")

def print_prediction_bar(all_probs, classes, predicted_idx):
    print("\nDETAYLI ANALÄ°Z:")
    probs_with_labels = [(classes[i], all_probs[i]*100) for i in range(len(classes))]
    probs_with_labels.sort(key=lambda x: x[1], reverse=True)
    
    for label, prob in probs_with_labels:
        bar_len = int(prob / 5)
        bar = "â–ˆ" * bar_len + "â–‘" * (20 - bar_len)
        tr = LABEL_TR.get(label, label)
        prefix = "ğŸ‘‰" if label == classes[predicted_idx] else "  "
        print(f"  {prefix} {tr:15} [{bar}] {prob:5.1f}%")

# =============================================================================
# MAIN
# =============================================================================
def main():
    yamnet, classifier, encoder = load_components()
    arduino = connect_arduino()
    
    device_index = select_microphone()
    block_size = int(SAMPLE_RATE * DURATION)
    classes = encoder.classes_
    
    print("\n" + "="*60)
    print(f"ğŸ¤ GELÄ°ÅMÄ°Å BEBEK AÄLAMASI ALGILAYICI (YAMNet)")
    print(f"â±ï¸  KayÄ±t SÃ¼resi: {DURATION} sn")
    print(f"ï¿½ï¸  GÃ¼ven EÅŸiÄŸi: %{CONFIDENCE_THRESHOLD}")
    print("="*60 + "\n")
    
    try:
        with sd.InputStream(samplerate=SAMPLE_RATE, channels=1, blocksize=block_size, device=device_index) as stream:
            while True:
                print(f"â³ {DURATION}sn dinleniyor...", end="\r")
                
                audio_data, _ = stream.read(block_size)
                audio_np = audio_data.flatten()
                
                # RMS Kontrol
                rms = np.sqrt(np.mean(audio_np**2))
                
                if rms < RMS_THRESHOLD:
                    print(f"ğŸ”‡ Ã‡ok Sesiz (RMS: {rms:.4f})                ", end="\r")
                    continue
                
                # Kaydet
                save_recording(audio_np, SAMPLE_RATE, "detected_yamnet")
                print(f"\n\nğŸ“¢ SES ALGILANDI (RMS: {rms:.4f})")
                
                try:
                    # 1. YAMNet'ten geÃ§ir
                    embedding = extract_embedding(yamnet, audio_np)
                    
                    # 2. SÄ±nÄ±flandÄ±r
                    prediction = classifier.predict(embedding, verbose=0)[0]
                    
                    predicted_index = np.argmax(prediction)
                    confidence = prediction[predicted_index] * 100
                    
                    if confidence < CONFIDENCE_THRESHOLD:
                        print(f"âš ï¸  DÃ¼ÅŸÃ¼k GÃ¼ven (%{confidence:.1f}).")
                        print_prediction_bar(prediction, classes, predicted_index)
                    else:
                        predicted_label = encoder.inverse_transform([predicted_index])[0]
                        tr_label = LABEL_TR.get(predicted_label, predicted_label)
                        
                        print(f"ğŸ¯ TESPÄ°T: {tr_label}")
                        print(f"âœ… GÃ¼ven:  %{confidence:.1f}")
                        print_prediction_bar(prediction, classes, predicted_index)
                        
                        # Arduino'ya gÃ¶nder
                        send_to_arduino(arduino, tr_label, confidence)
                        
                    print("-" * 50)
                    
                except Exception as e:
                    print(f"âŒ Analiz HatasÄ±: {e}")
                    import traceback
                    traceback.print_exc()

    except KeyboardInterrupt:
        print("\nğŸ›‘ Ã‡Ä±kÄ±ÅŸ.")

if __name__ == "__main__":
    main()
